군자동 음식점-리뷰 500개 이상-[업소명, 고유 번호, 리뷰]</br>
vscode 01_25 파일의 try2 코드임</br>

## Import
```python
from selenium.webdriver.common.by import By
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from openpyxl import Workbook
from bs4 import BeautifulSoup
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.keys import Keys
import time
import datetime
import requests
import pandas as pd
```

## 기본 데이터
```python
name = pd.DataFrame({'업소명' : ['버거킹 군자능동점', '빠오즈푸 본점', '숙성부심', '영미오리탕', '싸다김밥 어린이대공원역점', '산들', '은혜즉석떡볶이', '능동아구찜', '보승회관 군자역점',
                            '미식반점 군자본점', '미식일가', '스위트앤카츠', '스시노칸도 어린이대공원역점', '천미향', '하이난', '샐러디 군자역점', '기와집 능이백숙삼계탕 본점',
                            '한촌설렁탕 군자점', '카레당', '하오츠', '새벽집군자점', '능동국시', '군자김밥 군자본점', '또래끼리', '세종원 군자본점', '화양리정육식당',
                            '고봉민김밥인 서울군자점', '돈카와치 어린이대공원점', '얌샘김밥 세종대점', '스시교센', '채선당 월남쌈 & 샤브샤브 화양점', '혼다라멘 어린이대공원점',
                            '장어시대 군자점', '만게츠', '알고', '라운지앤', '용두동할매쭈꾸미', '장수마을 정육식당', '무한정수제돈까스 군자점', '피자스쿨 세종대점', '미주류 본점',
                            '담꾹 군자점', '본죽 군자역점', '심야식당쿠난', '요마시', '이삭토스트 세종대점', '뉴욕떡볶이', '섬진강민물장어', '봉추찜닭 군자역점', '60계치킨 군자점',
                            '광나루유황오리주물럭']})

num = pd.DataFrame({'고유번호' : [1511881360, 20757891, 1178891712, 11687205, 1981065688,
                              31234534, 20912981, 13199247, 1827382271, 1472793185,
                              36215038, 36481365, 1156658135, 12035278, 11611452,
                              1733116910, 34320746, 1900231521, 1254145458, 37101744,
                              38010611, 38275086, 1155648623, 37213189, 34628680,
                              1947162354, 35044920, 1542379601, 1234257499, 1875865667,
                              21693162, 1085950217, 1548611684, 1503215430, 810682299,
                              32822240, 12901119, 21597707, 32848507, 20943449,
                              1331438803, 1849204025, 13337899, 1847664192, 1867205146,
                              20893928, 37358975, 1189624815, 11598457, 1429755390,
                              20931930]})
```

## 코드
```python
all_reviews = []

for i in num['고유번호']:
    contents = []

    # url
    url = 'https://m.place.naver.com/restaurant/' + str(i) + '/review/visitor'

    # Webdriver headless mode setting
    options = webdriver.ChromeOptions()
    options.add_argument('window-size=1920x1080')
    options.add_argument("disable-gpu")

    # BS4 setting for secondary access
    session = requests.Session()
    headers = {
        "User-Agent": "user value"}

    retries = Retry(total=5,
                    backoff_factor=0.1,
                    status_forcelist=[500, 502, 503, 504])

    session.mount('http://', HTTPAdapter(max_retries=retries))


    # Start crawling/scraping!
    try:
        service = webdriver.ChromeService(executable_path=ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        res = driver.get(url)
        driver.implicitly_wait(30)

        # Pagedown
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)

        try:
            while True:
                driver.find_element(By.XPATH, '//*[@id="app-root"]/div/div/div/div[6]/div[2]/div[3]/div[2]/div/a').click()
                time.sleep(0.4)
        except Exception as e:
            print('finish')

        time.sleep(25)
        html = driver.page_source
        bs = BeautifulSoup(html, 'lxml')
        reviews = bs.select('li.YeINN')

        for r in reviews:
            content = r.select_one('div.ZZ4OK.IwhtZ')

            # exception handling
            content = content.text if content else ''
            contents.append(content)
            time.sleep(0.06)
        
        all_reviews.append(contents)


    except Exception as e:
        print(e)
```

## 마무리
```python
res = pd.DataFrame({'리뷰' : all_reviews})
res_tot = pd.concat([name, num, res], axis=1)
res_tot.to_csv("data_all_tot_01260247.csv", encoding='utf-8-sig')
```
